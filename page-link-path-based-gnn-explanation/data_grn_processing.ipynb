{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/younggun0816/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import os\n",
    "from utils import eids_split, remove_all_edges_of_etype, get_num_nodes_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_grn_data(g,\n",
    "                     val_ratio,\n",
    "                     test_ratio,\n",
    "                     neg):\n",
    "    \n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    g : dgl graph\n",
    "    \n",
    "    val_ratio : float\n",
    "    \n",
    "    test_ratio : float\n",
    "    \n",
    "    neg: string\n",
    "        One of ['pred_etype_neg', 'src_tgt_neg'], different negative sampling modes. See below.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    mp_g: \n",
    "        graph for message passing.\n",
    "    \n",
    "    graphs containing positive edges and negative edges for train, valid, and test\n",
    "    '''\n",
    "    \n",
    "    u, v = g.edges()\n",
    "\n",
    "    M = u.shape[0] # number of edges\n",
    "    eids = torch.arange(M)\n",
    "    train_pos_eids, val_pos_eids, test_pos_eids = eids_split(eids, val_ratio, test_ratio)\n",
    "\n",
    "    train_pos_u, train_pos_v = u[train_pos_eids], v[train_pos_eids]\n",
    "    val_pos_u, val_pos_v = u[val_pos_eids], v[val_pos_eids]\n",
    "    test_pos_u, test_pos_v = u[test_pos_eids], v[test_pos_eids]\n",
    "\n",
    "    if neg == 'pred_etype_neg':\n",
    "        # Edges not in pred_etype as negative edges\n",
    "        adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())), shape=(g.num_nodes(), g.num_nodes()))\n",
    "        adj_neg = 1 - adj.todense()\n",
    "        neg_u, neg_v = np.where(adj_neg != 0)\n",
    "    else:\n",
    "        raise ValueError('Unknow negative argument')\n",
    "        \n",
    "    neg_eids = np.random.choice(neg_u.shape[0], min(neg_u.shape[0], M), replace=False)\n",
    "    train_neg_eids, val_neg_eids, test_neg_eids = eids_split(torch.from_numpy(neg_eids), val_ratio, test_ratio)\n",
    "\n",
    "    # Avoid losing dimension in single number slicing\n",
    "    train_neg_u, train_neg_v = np.take(neg_u, train_neg_eids), np.take(neg_v, train_neg_eids)\n",
    "    val_neg_u, val_neg_v = np.take(neg_u, val_neg_eids),np.take(neg_v, val_neg_eids)\n",
    "    test_neg_u, test_neg_v = np.take(neg_u, test_neg_eids), np.take(neg_v, test_neg_eids)\n",
    "\n",
    "\n",
    "    train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.num_nodes())\n",
    "    train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.num_nodes())\n",
    "    val_pos_g = dgl.graph((val_pos_u, val_pos_v), num_nodes=g.num_nodes())\n",
    "    val_neg_g = dgl.graph((val_neg_u, val_neg_v), num_nodes=g.num_nodes())\n",
    "    test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.num_nodes())\n",
    "\n",
    "    test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.num_nodes())\n",
    "        # Create message passing graph by removing all edges (그러나 엣지 타입의 구분이 없기때문에 동일.)\n",
    "    mp_g = g\n",
    "\n",
    "    return mp_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_grn_dataset(dataset_dir, dataset_name, val_ratio, test_ratio):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_dir : string\n",
    "        dataset directory\n",
    "    \n",
    "    dataset_name : string\n",
    "    \n",
    "    val_ratio : float\n",
    "    \n",
    "    test_ratio : float\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    g: dgl graph\n",
    "        The original graph\n",
    "\n",
    "    processed_g: tuple of seven dgl graphs\n",
    "        The outputs of the function `process_data`, \n",
    "        which includes g for message passing, train, valid, and test\n",
    "  \n",
    "    '''\n",
    "    graph_saving_path = f'{dataset_dir}/{dataset_name}'\n",
    "    graph_list, _ = dgl.load_graphs(graph_saving_path)\n",
    "    g = graph_list[0] # 리스트로 반환되나 실상 단일 그래프이므로.\n",
    " \n",
    "    neg = 'pred_etype_neg'\n",
    "    processed_g = process_grn_data(g, val_ratio, test_ratio, neg)\n",
    "    return g, processed_g\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_label_creation(ecoli1_gold,edge_list):\n",
    "\n",
    "   edge_df = pd.DataFrame(edge_list, columns =['source', 'target'])\n",
    "   ecoli1_gold[0] = ecoli1_gold[0].str.replace('G', '')\n",
    "   ecoli1_gold[1] = ecoli1_gold[1].str.replace('G', '')\n",
    "   ecoli1_gold= ecoli1_gold.astype(int)\n",
    "   ecoli1_gold[0] = ecoli1_gold[0] - 1\n",
    "   ecoli1_gold[1] = ecoli1_gold[1] - 1\n",
    "\n",
    "   edge_df['edge'] = 0\n",
    "   for i in range(ecoli1_gold.shape[0]):\n",
    "         r = ecoli1_gold.iat[i,0]\n",
    "         c = ecoli1_gold.iat[i,1]\n",
    "         idx= edge_df.loc[(edge_df['source'] == r) & (edge_df['target'] == c)].index\n",
    "         edge_df.loc[idx,'edge']=ecoli1_gold.iat[i,2]\n",
    "   return edge_df\n",
    "\n",
    "\n",
    "def save_graphs_to_folder(graphs, folder_path):\n",
    "    \"\"\"\n",
    "    DGL 그래프들을 지정된 폴더에 저장하는 함수.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    graphs : dict\n",
    "        저장할 그래프 딕셔너리. 키는 그래프 이름, 값은 DGL 그래프.\n",
    "    folder_path : str\n",
    "        그래프를 저장할 폴더 경로.\n",
    "    \"\"\"\n",
    "    # 폴더가 존재하지 않으면 생성\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    # 그래프 저장\n",
    "    for graph_name, graph in graphs.items():\n",
    "        save_path = os.path.join(folder_path, f\"{graph_name}.bin\")\n",
    "        dgl.save_graphs(save_path, graph)\n",
    "        print(f\"그래프 '{graph_name}'이(가) {save_path}에 저장되었습니다.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_grn_to_dgl_graph(file_hetero,file_null,file_traject,file_gold):\n",
    "    \"\"\"\n",
    "    GRN 데이터를 DGL 그래프 형태로 변환하는 함수\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    node_file : str\n",
    "        노드 특징이 포함된 파일 경로\n",
    "    edge_file : str\n",
    "        엣지 데이터가 포함된 파일 경로\n",
    "    gold_file : str\n",
    "        라벨링된 표준(Gold Standard) 파일 경로\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    dgl_graph : dgl.DGLGraph\n",
    "        DGL 그래프 객체\n",
    "    \"\"\"\n",
    "    default_path=\"./data/DREAM4/DREAM4_InSilico_Size100/\"#+folder_name+\"/\"+folder_name+\"/\"\n",
    "    default_goldpath=\"./data/DREAM4/gold_std/\"\n",
    "\n",
    "    # Load data\n",
    "    hetero = pd.read_csv(default_path + file_hetero, sep='\\t')\n",
    "    null = pd.read_csv(default_path + file_null, sep='\\t')\n",
    "    traject = pd.read_csv(default_path + file_traject, sep='\\t')\n",
    "    gold = pd.read_csv(default_goldpath + file_gold, sep='\\t', header=None)\n",
    "\n",
    "    # Extract wildtype values\n",
    "    wildtype_vals = hetero.loc[1, :].values.tolist()\n",
    "    hetero['id'] = hetero.index\n",
    "    \n",
    "    # Create node features\n",
    "    node_features = hetero[['id']]\n",
    "    node_features['wildtype'] = wildtype_vals\n",
    "\n",
    "    traj = traject.T.iloc[1:, 1:]\n",
    "    traj = traj.reset_index()\n",
    "    node_features = pd.concat([node_features, traj], axis=1)\n",
    "    node_features = node_features.drop(['index'], axis=1)\n",
    "\n",
    "    # Extract edge features and edge labels\n",
    "    edge_list = list(itertools.product(node_features[\"id\"], repeat=2))\n",
    "    edge_lab = edge_label_creation(gold, edge_list)\n",
    "\n",
    "    null = null.iloc[1:, :].reset_index(drop=True)\n",
    "    null_list = null.values.flatten()\n",
    "\n",
    "    hetero = hetero.iloc[1:, :].reset_index(drop=True).drop(['id'], axis=1)\n",
    "    hetero_list = hetero.values.flatten()\n",
    "\n",
    "    edge_lab.columns = ['s', 'd', 'edge']\n",
    "    edge_lab = edge_lab.iloc[100:].reset_index(drop=True)\n",
    "    edge_lab['KO'] = null_list\n",
    "    edge_lab['KD'] = hetero_list\n",
    "    edge_lab = edge_lab[edge_lab['edge'] == 1]\n",
    "\n",
    "    # Extract source, destination, and edge attributes\n",
    "    src = edge_lab[\"s\"].tolist()\n",
    "    dst = edge_lab['d'].tolist()\n",
    "    KO = edge_lab[\"KO\"].tolist()\n",
    "    KD = edge_lab[\"KD\"].tolist()\n",
    "\n",
    "    # Create DGL graph for basic_data\n",
    "    g_basic = dgl.graph((src, dst))\n",
    "    id_tensor = torch.tensor(node_features['id'].tolist(), dtype=torch.float32).view(-1, 1)\n",
    "    wildtype_tensor = torch.tensor(node_features['wildtype'].tolist(), dtype=torch.float32).view(-1, 1)\n",
    "    g_basic.ndata['id'] = id_tensor\n",
    "    g_basic.ndata['wildtype'] = wildtype_tensor\n",
    "    g_basic.edata['KO'] = torch.tensor(KO, dtype=torch.float32).view(-1, 1)\n",
    "    g_basic.edata['KD'] = torch.tensor(KD, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    # Create DGL graph for basic_TS_data\n",
    "    g_basic_TS = g_basic.clone()\n",
    "    traj_tensor = torch.tensor(node_features.iloc[:, 2:].values, dtype=torch.float32)\n",
    "    g_basic_TS.ndata['trajectory'] = traj_tensor\n",
    "\n",
    "    # Create DGL graph for basic_aug_data\n",
    "    G = g_basic.to_networkx().to_undirected()\n",
    "    pagerank = nx.pagerank(G)\n",
    "    clustering_coef = nx.clustering(G)\n",
    "    betweenness_centrality = nx.betweenness_centrality(G, k=50)\n",
    "    degree = dict(G.degree())\n",
    "\n",
    "    pagerank_tensor = torch.tensor([pagerank[i] for i in range(len(pagerank))], dtype=torch.float32).view(-1, 1)\n",
    "    clustering_tensor = torch.tensor([clustering_coef[i] for i in range(len(clustering_coef))], dtype=torch.float32).view(-1, 1)\n",
    "    betweenness_tensor = torch.tensor([betweenness_centrality[i] for i in range(len(betweenness_centrality))], dtype=torch.float32).view(-1, 1)\n",
    "    degree_tensor = torch.tensor([degree[i] for i in range(len(degree))], dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    g_basic_aug = g_basic.clone()\n",
    "    g_basic_aug.ndata['pagerank'] = pagerank_tensor\n",
    "    g_basic_aug.ndata['clustering_coef'] = clustering_tensor\n",
    "    g_basic_aug.ndata['betweenness'] = betweenness_tensor\n",
    "    g_basic_aug.ndata['degree'] = degree_tensor\n",
    "\n",
    "    # Create DGL graph for basic_TS_aug_data\n",
    "    g_basic_TS_aug = g_basic_TS.clone()\n",
    "    g_basic_TS_aug.ndata['pagerank'] = pagerank_tensor\n",
    "    g_basic_TS_aug.ndata['clustering_coef'] = clustering_tensor\n",
    "    g_basic_TS_aug.ndata['betweenness'] = betweenness_tensor\n",
    "    g_basic_TS_aug.ndata['degree'] = degree_tensor\n",
    "\n",
    "    print(\"Basic Graph:\", g_basic)\n",
    "    print(\"Basic TS Graph:\", g_basic_TS)\n",
    "    print(\"Basic Augmented Graph:\", g_basic_aug)\n",
    "    print(\"Basic TS Augmented Graph:\", g_basic_TS_aug)\n",
    "\n",
    "\n",
    "    # 그래프를 저장할 폴더 경로\n",
    "    folder_path = \"./datasets\"\n",
    "\n",
    "    # 그래프를 딕셔너리로 저장\n",
    "    graphs = {\n",
    "        \"basic_graph\": g_basic,\n",
    "        \"basic_ts_graph\": g_basic_TS,\n",
    "        \"basic_aug_graph\": g_basic_aug,\n",
    "        \"basic_ts_aug_graph\": g_basic_TS_aug\n",
    "    }\n",
    "\n",
    "    # 그래프 저장\n",
    "    save_graphs_to_folder(graphs, folder_path)\n",
    "    \n",
    "    return g_basic, g_basic_TS, g_basic_aug, g_basic_TS_aug\n",
    "\n",
    "# Example usage:\n",
    "# g_basic, g_basic_TS, g_basic_aug, g_basic_TS_aug = data_preprocessing_dgl('folder_name', 'file_hetero.tsv', 'file_null.tsv', 'file_traject.tsv', 'file_gold.tsv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path for the files\n",
    "gold_std = \"./data/DREAM4/gold_std/\"\n",
    "\n",
    "InsilicoSize100_org  = {\"Ecoli1\":  [\"InSilicoSize100\",\"insilico_size100_1_knockdowns.tsv\",\"insilico_size100_1_knockouts.tsv\",\"insilico_size100_1_timeseries.tsv\",\"DREAM4_GoldStandard_InSilico_Size100_1.tsv\"],\n",
    "                       \"Ecoli2\":  [\"InSilicoSize100\",\"insilico_size100_2_knockdowns.tsv\",\"insilico_size100_2_knockouts.tsv\",\"insilico_size100_2_timeseries.tsv\",\"DREAM4_GoldStandard_InSilico_Size100_2.tsv\"],\n",
    "                       \"Yeast1\":  [\"InSilicoSize100\",\"insilico_size100_3_knockdowns.tsv\",\"insilico_size100_3_knockouts.tsv\",\"insilico_size100_3_timeseries.tsv\",\"DREAM4_GoldStandard_InSilico_Size100_3.tsv\"],\n",
    "                       \"Yeast2\":  [\"InSilicoSize100\",\"insilico_size100_4_knockdowns.tsv\",\"insilico_size100_4_knockouts.tsv\",\"insilico_size100_4_timeseries.tsv\",\"DREAM4_GoldStandard_InSilico_Size100_4.tsv\"],\n",
    "                       \"Yeast3\":  [\"InSilicoSize100\",\"insilico_size100_5_knockdowns.tsv\",\"insilico_size100_5_knockouts.tsv\",\"insilico_size100_5_timeseries.tsv\",\"DREAM4_GoldStandard_InSilico_Size100_5.tsv\"]\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1461695/3510275876.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  node_features['wildtype'] = wildtype_vals\n"
     ]
    },
    {
     "ename": "NetworkXNotImplemented",
     "evalue": "not implemented for multigraph type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNetworkXNotImplemented\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/DREAM4/DREAM4_InSilico_Size100/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m org, files \u001b[38;5;129;01min\u001b[39;00m InsilicoSize100_org\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 3\u001b[0m     basic_data,basic_TS_data,basic_aug_data,basic_TS_aug_data \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_grn_to_dgl_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 80\u001b[0m, in \u001b[0;36mconvert_grn_to_dgl_graph\u001b[0;34m(file_hetero, file_null, file_traject, file_gold)\u001b[0m\n\u001b[1;32m     78\u001b[0m G \u001b[38;5;241m=\u001b[39m g_basic\u001b[38;5;241m.\u001b[39mto_networkx()\u001b[38;5;241m.\u001b[39mto_undirected()\n\u001b[1;32m     79\u001b[0m pagerank \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mpagerank(G)\n\u001b[0;32m---> 80\u001b[0m clustering_coef \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclustering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m betweenness_centrality \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mbetweenness_centrality(G, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m     82\u001b[0m degree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(G\u001b[38;5;241m.\u001b[39mdegree())\n",
      "File \u001b[0;32m~/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/networkx/utils/backends.py:412\u001b[0m, in \u001b[0;36m_dispatch.__call__\u001b[0;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backends:\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;66;03m# Fast path if no backends are installed\u001b[39;00m\n\u001b[0;32m--> 412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morig_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# Use `backend_name` in this function instead of `backend`\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m backend\n",
      "File \u001b[0;32m~/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/networkx/algorithms/cluster.py:419\u001b[0m, in \u001b[0;36mclustering\u001b[0;34m(G, nodes, weight)\u001b[0m\n\u001b[1;32m    417\u001b[0m         clusterc \u001b[38;5;241m=\u001b[39m {v: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t \u001b[38;5;241m/\u001b[39m (d \u001b[38;5;241m*\u001b[39m (d \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m v, d, t \u001b[38;5;129;01min\u001b[39;00m td_iter}\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m         td_iter \u001b[38;5;241m=\u001b[39m \u001b[43m_triangles_and_degree_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m         clusterc \u001b[38;5;241m=\u001b[39m {v: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t \u001b[38;5;241m/\u001b[39m (d \u001b[38;5;241m*\u001b[39m (d \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m v, d, t, _ \u001b[38;5;129;01min\u001b[39;00m td_iter}\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nodes \u001b[38;5;129;01min\u001b[39;00m G:\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# Return the value of the sole entry in the dictionary.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/networkx/utils/decorators.py:770\u001b[0m, in \u001b[0;36margmap.__call__.<locals>.func\u001b[0;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(\u001b[38;5;241m*\u001b[39margs, __wrapper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 770\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43margmap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__wrapper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 4:3\u001b[0m, in \u001b[0;36margmap__triangles_and_degree_iter_1\u001b[0;34m(G, nodes)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbz2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/networkx/utils/decorators.py:90\u001b[0m, in \u001b[0;36mnot_implemented_for.<locals>._not_implemented_for\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_not_implemented_for\u001b[39m(g):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (mval \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m mval \u001b[38;5;241m==\u001b[39m g\u001b[38;5;241m.\u001b[39mis_multigraph()) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m     88\u001b[0m         dval \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m dval \u001b[38;5;241m==\u001b[39m g\u001b[38;5;241m.\u001b[39mis_directed()\n\u001b[1;32m     89\u001b[0m     ):\n\u001b[0;32m---> 90\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m nx\u001b[38;5;241m.\u001b[39mNetworkXNotImplemented(errmsg)\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m g\n",
      "\u001b[0;31mNetworkXNotImplemented\u001b[0m: not implemented for multigraph type"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"./data/DREAM4/DREAM4_InSilico_Size100/\"\n",
    "for org, files in InsilicoSize100_org.items():\n",
    "    basic_data,basic_TS_data,basic_aug_data,basic_TS_aug_data = convert_grn_to_dgl_graph(files[1],files[2],files[3],files[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GRNXAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
