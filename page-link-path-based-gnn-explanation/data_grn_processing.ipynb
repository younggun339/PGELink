{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import os\n",
    "from utils import eids_split, remove_all_edges_of_etype, get_num_nodes_dict\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_grn_data(g,\n",
    "                     val_ratio,\n",
    "                     test_ratio,\n",
    "                     neg):\n",
    "    \n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    g : dgl graph\n",
    "    \n",
    "    val_ratio : float\n",
    "    \n",
    "    test_ratio : float\n",
    "    \n",
    "    neg: string\n",
    "        One of ['pred_etype_neg', 'src_tgt_neg'], different negative sampling modes. See below.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    mp_g: \n",
    "        graph for message passing.\n",
    "    \n",
    "    graphs containing positive edges and negative edges for train, valid, and test\n",
    "    '''\n",
    "    \n",
    "    u, v = g.edges()\n",
    "\n",
    "    M = u.shape[0] # number of edges\n",
    "    eids = torch.arange(M)\n",
    "    train_pos_eids, val_pos_eids, test_pos_eids = eids_split(eids, val_ratio, test_ratio)\n",
    "\n",
    "    train_pos_u, train_pos_v = u[train_pos_eids], v[train_pos_eids]\n",
    "    val_pos_u, val_pos_v = u[val_pos_eids], v[val_pos_eids]\n",
    "    test_pos_u, test_pos_v = u[test_pos_eids], v[test_pos_eids]\n",
    "\n",
    "    if neg == 'pred_etype_neg':\n",
    "        # Edges not in pred_etype as negative edges\n",
    "        adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())), shape=(g.num_nodes(), g.num_nodes()))\n",
    "        adj_neg = 1 - adj.todense()\n",
    "        neg_u, neg_v = np.where(adj_neg != 0)\n",
    "    else:\n",
    "        raise ValueError('Unknow negative argument')\n",
    "        \n",
    "    neg_eids = np.random.choice(neg_u.shape[0], min(neg_u.shape[0], M), replace=False)\n",
    "    train_neg_eids, val_neg_eids, test_neg_eids = eids_split(torch.from_numpy(neg_eids), val_ratio, test_ratio)\n",
    "\n",
    "    # Avoid losing dimension in single number slicing\n",
    "    train_neg_u, train_neg_v = np.take(neg_u, train_neg_eids), np.take(neg_v, train_neg_eids)\n",
    "    val_neg_u, val_neg_v = np.take(neg_u, val_neg_eids),np.take(neg_v, val_neg_eids)\n",
    "    test_neg_u, test_neg_v = np.take(neg_u, test_neg_eids), np.take(neg_v, test_neg_eids)\n",
    "\n",
    "\n",
    "    train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.num_nodes())\n",
    "    train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.num_nodes())\n",
    "    val_pos_g = dgl.graph((val_pos_u, val_pos_v), num_nodes=g.num_nodes())\n",
    "    val_neg_g = dgl.graph((val_neg_u, val_neg_v), num_nodes=g.num_nodes())\n",
    "    test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.num_nodes())\n",
    "\n",
    "    test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.num_nodes())\n",
    "        # Create message passing graph by removing all edges (그러나 엣지 타입의 구분이 없기때문에 동일.)\n",
    "    mp_g = g\n",
    "\n",
    "    return mp_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_grn_dataset(dataset_dir, dataset_name, val_ratio, test_ratio):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_dir : string\n",
    "        dataset directory\n",
    "    \n",
    "    dataset_name : string\n",
    "    \n",
    "    val_ratio : float\n",
    "    \n",
    "    test_ratio : float\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    g: dgl graph\n",
    "        The original graph\n",
    "\n",
    "    processed_g: tuple of seven dgl graphs\n",
    "        The outputs of the function `process_data`, \n",
    "        which includes g for message passing, train, valid, and test\n",
    "  \n",
    "    '''\n",
    "    graph_saving_path = f'{dataset_dir}/{dataset_name}'\n",
    "    graph_list, _ = dgl.load_graphs(graph_saving_path)\n",
    "    g = graph_list[0] # 리스트로 반환되나 실상 단일 그래프이므로.\n",
    " \n",
    "    neg = 'pred_etype_neg'\n",
    "    processed_g = process_grn_data(g, val_ratio, test_ratio, neg)\n",
    "    return g, processed_g\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_label_creation(ecoli1_gold,edge_list):\n",
    "\n",
    "   edge_df = pd.DataFrame(edge_list, columns =['source', 'target'])\n",
    "   ecoli1_gold[0] = ecoli1_gold[0].str.replace('G', '')\n",
    "   ecoli1_gold[1] = ecoli1_gold[1].str.replace('G', '')\n",
    "   ecoli1_gold= ecoli1_gold.astype(int)\n",
    "   ecoli1_gold[0] = ecoli1_gold[0] - 1\n",
    "   ecoli1_gold[1] = ecoli1_gold[1] - 1\n",
    "\n",
    "   edge_df['edge'] = 0\n",
    "   for i in range(ecoli1_gold.shape[0]):\n",
    "         r = ecoli1_gold.iat[i,0]\n",
    "         c = ecoli1_gold.iat[i,1]\n",
    "         idx= edge_df.loc[(edge_df['source'] == r) & (edge_df['target'] == c)].index\n",
    "         edge_df.loc[idx,'edge']=ecoli1_gold.iat[i,2]\n",
    "   return edge_df\n",
    "\n",
    "\n",
    "def save_graphs_to_folder(graphs, folder_path):\n",
    "    \"\"\"\n",
    "    DGL 그래프들을 지정된 폴더에 저장하는 함수.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    graphs : dict\n",
    "        저장할 그래프 딕셔너리. 키는 그래프 이름, 값은 DGL 그래프.\n",
    "    folder_path : str\n",
    "        그래프를 저장할 폴더 경로.\n",
    "    \"\"\"\n",
    "    # 폴더가 존재하지 않으면 생성\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    # 그래프 저장\n",
    "    for graph_name, graph in graphs.items():\n",
    "        save_path = os.path.join(folder_path, f\"{graph_name}.bin\")\n",
    "        dgl.save_graphs(save_path, graph)\n",
    "        print(f\"그래프 '{graph_name}'이(가) {save_path}에 저장되었습니다.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_grn_to_dgl_graph(file_hetero,file_null,file_traject,file_gold):\n",
    "    \"\"\"\n",
    "    GRN 데이터를 DGL 그래프 형태로 변환하는 함수\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    node_file : str\n",
    "        노드 특징이 포함된 파일 경로\n",
    "    edge_file : str\n",
    "        엣지 데이터가 포함된 파일 경로\n",
    "    gold_file : str\n",
    "        라벨링된 표준(Gold Standard) 파일 경로\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    dgl_graph : dgl.DGLGraph\n",
    "        DGL 그래프 객체\n",
    "    \"\"\"\n",
    "    default_path=\"./data/DREAM4/DREAM4_InSilico_Size100/\"#+folder_name+\"/\"+folder_name+\"/\"\n",
    "    default_goldpath=\"./data/DREAM4/gold_std/\"\n",
    "\n",
    "    # Load data\n",
    "    hetero = pd.read_csv(default_path + file_hetero, sep='\\t')\n",
    "    null = pd.read_csv(default_path + file_null, sep='\\t')\n",
    "    traject = pd.read_csv(default_path + file_traject, sep='\\t')\n",
    "    gold = pd.read_csv(default_goldpath + file_gold, sep='\\t', header=None)\n",
    "\n",
    "    # Extract wildtype values\n",
    "    wildtype_vals = hetero.loc[1, :].values.tolist()\n",
    "    hetero['id'] = hetero.index\n",
    "    \n",
    "    # Create node features\n",
    "    node_features = hetero[['id']]\n",
    "    node_features['wildtype'] = wildtype_vals\n",
    "\n",
    "    traj = traject.T.iloc[1:, 1:]\n",
    "    traj = traj.reset_index()\n",
    "    node_features = pd.concat([node_features, traj], axis=1)\n",
    "    node_features = node_features.drop(['index'], axis=1)\n",
    "\n",
    "    # Extract edge features and edge labels\n",
    "    edge_list = list(itertools.product(node_features[\"id\"], repeat=2))\n",
    "    edge_lab = edge_label_creation(gold, edge_list)\n",
    "\n",
    "    null = null.iloc[1:, :].reset_index(drop=True)\n",
    "    null_list = null.values.flatten()\n",
    "\n",
    "    hetero = hetero.iloc[1:, :].reset_index(drop=True).drop(['id'], axis=1)\n",
    "    hetero_list = hetero.values.flatten()\n",
    "\n",
    "    edge_lab.columns = ['s', 'd', 'edge']\n",
    "    edge_lab = edge_lab.iloc[100:].reset_index(drop=True)\n",
    "    edge_lab['KO'] = null_list\n",
    "    edge_lab['KD'] = hetero_list\n",
    "    edge_lab = edge_lab[edge_lab['edge'] == 1]\n",
    "\n",
    "    # Extract source, destination, and edge attributes\n",
    "    src = edge_lab[\"s\"].tolist()\n",
    "    dst = edge_lab['d'].tolist()\n",
    "    #######디버깅 코드1\n",
    "    # src와 dst 생성 확인\n",
    "    print(\"Source nodes:\", src[:10])  # src의 일부 확인\n",
    "    print(\"Destination nodes:\", dst[:10])  # dst의 일부 확인\n",
    "\n",
    "    # edge_lab 데이터에서 source와 destination 간선 중복 확인\n",
    "    edge_lab_pairs = list(zip(edge_lab[\"s\"], edge_lab[\"d\"]))\n",
    "    edge_lab_counts = Counter(edge_lab_pairs)\n",
    "\n",
    "    # 중복 간선 확인\n",
    "    duplicates_in_edge_lab = {edge: count for edge, count in edge_lab_counts.items() if count > 1}\n",
    "    print(\"edge_lab 중복 간선:\", duplicates_in_edge_lab)\n",
    "    ########\n",
    "    KO = edge_lab[\"KO\"].tolist()\n",
    "    KD = edge_lab[\"KD\"].tolist()\n",
    "\n",
    "    # Create DGL graph for basic_data\n",
    "    g_basic = dgl.graph((src, dst))\n",
    "    id_tensor = torch.tensor(node_features['id'].tolist(), dtype=torch.float32).view(-1, 1)\n",
    "    wildtype_tensor = torch.tensor(node_features['wildtype'].tolist(), dtype=torch.float32).view(-1, 1)\n",
    "    g_basic.ndata['id'] = id_tensor\n",
    "    g_basic.ndata['wildtype'] = wildtype_tensor\n",
    "    g_basic.edata['KO'] = torch.tensor(KO, dtype=torch.float32).view(-1, 1)\n",
    "    g_basic.edata['KD'] = torch.tensor(KD, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    ######\n",
    "    # g_basic의 간선 데이터 확인\n",
    "    src, dst = g_basic.edges()\n",
    "\n",
    "    # (source, destination) 튜플로 간선 리스트 생성\n",
    "    edges = list(zip(src.tolist(), dst.tolist()))\n",
    "\n",
    "    # 중복된 간선 확인\n",
    "    \n",
    "    edge_counts = Counter(edges)\n",
    "\n",
    "    # 중복 간선 출력\n",
    "    duplicates = {edge: count for edge, count in edge_counts.items() if count > 1}\n",
    "    print(\"중복 간선:\", duplicates)\n",
    "\n",
    "    #####\n",
    "    # Create DGL graph for basic_TS_data\n",
    "    g_basic_TS = g_basic.clone()\n",
    "    traj_tensor = torch.tensor(node_features.iloc[:, 2:].values, dtype=torch.float32)\n",
    "    g_basic_TS.ndata['trajectory'] = traj_tensor\n",
    "\n",
    "    # Create DGL graph for basic_aug_data\n",
    "    G = g_basic.to_networkx().to_undirected()\n",
    "    ############\n",
    "    print(type(G))  # <class 'networkx.classes.multigraph.MultiGraph'>이면 Multigraph로 변환된 것\n",
    "\n",
    "    # G의 중복 간선 확인\n",
    "    if isinstance(G, nx.MultiGraph):\n",
    "        multi_edges = list(G.edges(data=True))\n",
    "        print(\"Multigraph 간선:\", multi_edges)\n",
    "    ############    \n",
    "    pagerank = nx.pagerank(G)\n",
    "    clustering_coef = nx.clustering(G)\n",
    "    betweenness_centrality = nx.betweenness_centrality(G, k=50)\n",
    "    degree = dict(G.degree())\n",
    "\n",
    "    pagerank_tensor = torch.tensor([pagerank[i] for i in range(len(pagerank))], dtype=torch.float32).view(-1, 1)\n",
    "    clustering_tensor = torch.tensor([clustering_coef[i] for i in range(len(clustering_coef))], dtype=torch.float32).view(-1, 1)\n",
    "    betweenness_tensor = torch.tensor([betweenness_centrality[i] for i in range(len(betweenness_centrality))], dtype=torch.float32).view(-1, 1)\n",
    "    degree_tensor = torch.tensor([degree[i] for i in range(len(degree))], dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    g_basic_aug = g_basic.clone()\n",
    "    g_basic_aug.ndata['pagerank'] = pagerank_tensor\n",
    "    g_basic_aug.ndata['clustering_coef'] = clustering_tensor\n",
    "    g_basic_aug.ndata['betweenness'] = betweenness_tensor\n",
    "    g_basic_aug.ndata['degree'] = degree_tensor\n",
    "\n",
    "    # Create DGL graph for basic_TS_aug_data\n",
    "    g_basic_TS_aug = g_basic_TS.clone()\n",
    "    g_basic_TS_aug.ndata['pagerank'] = pagerank_tensor\n",
    "    g_basic_TS_aug.ndata['clustering_coef'] = clustering_tensor\n",
    "    g_basic_TS_aug.ndata['betweenness'] = betweenness_tensor\n",
    "    g_basic_TS_aug.ndata['degree'] = degree_tensor\n",
    "\n",
    "    print(\"Basic Graph:\", g_basic)\n",
    "    print(\"Basic TS Graph:\", g_basic_TS)\n",
    "    print(\"Basic Augmented Graph:\", g_basic_aug)\n",
    "    print(\"Basic TS Augmented Graph:\", g_basic_TS_aug)\n",
    "\n",
    "\n",
    "    # 그래프를 저장할 폴더 경로\n",
    "    folder_path = \"./datasets\"\n",
    "\n",
    "    # 그래프를 딕셔너리로 저장\n",
    "    graphs = {\n",
    "        \"basic_graph\": g_basic,\n",
    "        \"basic_ts_graph\": g_basic_TS,\n",
    "        \"basic_aug_graph\": g_basic_aug,\n",
    "        \"basic_ts_aug_graph\": g_basic_TS_aug\n",
    "    }\n",
    "\n",
    "    # 그래프 저장\n",
    "    save_graphs_to_folder(graphs, folder_path)\n",
    "    \n",
    "    return g_basic, g_basic_TS, g_basic_aug, g_basic_TS_aug\n",
    "\n",
    "# Example usage:\n",
    "# g_basic, g_basic_TS, g_basic_aug, g_basic_TS_aug = data_preprocessing_dgl('folder_name', 'file_hetero.tsv', 'file_null.tsv', 'file_traject.tsv', 'file_gold.tsv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path for the files\n",
    "gold_std = \"./data/DREAM4/gold_std/\"\n",
    "\n",
    "InsilicoSize100_org  = {\"Ecoli1\":  [\"InSilicoSize100\",\"insilico_size100_1_knockdowns.tsv\",\"insilico_size100_1_knockouts.tsv\",\"insilico_size100_1_timeseries.tsv\",\"DREAM4_GoldStandard_InSilico_Size100_1.tsv\"],\n",
    "                       \"Ecoli2\":  [\"InSilicoSize100\",\"insilico_size100_2_knockdowns.tsv\",\"insilico_size100_2_knockouts.tsv\",\"insilico_size100_2_timeseries.tsv\",\"DREAM4_GoldStandard_InSilico_Size100_2.tsv\"],\n",
    "                       \"Yeast1\":  [\"InSilicoSize100\",\"insilico_size100_3_knockdowns.tsv\",\"insilico_size100_3_knockouts.tsv\",\"insilico_size100_3_timeseries.tsv\",\"DREAM4_GoldStandard_InSilico_Size100_3.tsv\"],\n",
    "                       \"Yeast2\":  [\"InSilicoSize100\",\"insilico_size100_4_knockdowns.tsv\",\"insilico_size100_4_knockouts.tsv\",\"insilico_size100_4_timeseries.tsv\",\"DREAM4_GoldStandard_InSilico_Size100_4.tsv\"],\n",
    "                       \"Yeast3\":  [\"InSilicoSize100\",\"insilico_size100_5_knockdowns.tsv\",\"insilico_size100_5_knockouts.tsv\",\"insilico_size100_5_timeseries.tsv\",\"DREAM4_GoldStandard_InSilico_Size100_5.tsv\"]\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2559749/1885219478.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  node_features['wildtype'] = wildtype_vals\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source nodes: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "Destination nodes: [1, 2, 3, 5, 6, 7, 8, 9, 10, 11]\n",
      "edge_lab 중복 간선: {}\n",
      "중복 간선: {}\n",
      "<class 'networkx.classes.multigraph.MultiGraph'>\n",
      "Multigraph 간선: [(0, 36, {'id': 36}), (0, 41, {'id': 63}), (1, 4, {'id': 0}), (2, 4, {'id': 1}), (3, 4, {'id': 2}), (3, 45, {'id': 73}), (3, 84, {'id': 138}), (4, np.int64(5), {'id': 3}), (4, np.int64(6), {'id': 4}), (4, np.int64(7), {'id': 5}), (4, np.int64(8), {'id': 6}), (4, np.int64(9), {'id': 7}), (4, np.int64(10), {'id': 8}), (4, np.int64(11), {'id': 9}), (4, np.int64(12), {'id': 10}), (4, np.int64(13), {'id': 11}), (4, np.int64(14), {'id': 12}), (4, np.int64(15), {'id': 13}), (4, np.int64(16), {'id': 14}), (4, np.int64(17), {'id': 15}), (4, np.int64(18), {'id': 16}), (4, np.int64(19), {'id': 17}), (4, np.int64(20), {'id': 18}), (4, np.int64(21), {'id': 19}), (6, 24, {'id': 25}), (7, 36, {'id': 37}), (8, 37, {'id': 60}), (8, 45, {'id': 74}), (8, 84, {'id': 139}), (9, np.int64(36), {'id': 38}), (9, np.int64(43), {'id': 66}), (9, np.int64(49), {'id': 22}), (9, 45, {'id': 75}), (9, 61, {'id': 102}), (9, 95, {'id': 164}), (9, 99, {'id': 171}), (10, 84, {'id': 140}), (11, 84, {'id': 141}), (12, 84, {'id': 142}), (13, 14, {'id': 23}), (15, 45, {'id': 76}), (15, 84, {'id': 143}), (16, 45, {'id': 77}), (16, 84, {'id': 144}), (17, 45, {'id': 78}), (17, 84, {'id': 145}), (18, 62, {'id': 105}), (18, 82, {'id': 133}), (19, 62, {'id': 106}), (19, 82, {'id': 134}), (20, 90, {'id': 157}), (20, 95, {'id': 165}), (21, 45, {'id': 79}), (22, np.int64(23), {'id': 24}), (22, 36, {'id': 39}), (22, 71, {'id': 125}), (23, 36, {'id': 40}), (23, 45, {'id': 80}), (23, 71, {'id': 126}), (23, 74, {'id': 130}), (24, 36, {'id': 41}), (24, 84, {'id': 146}), (25, np.int64(26), {'id': 26}), (25, np.int64(27), {'id': 27}), (25, np.int64(28), {'id': 28}), (25, np.int64(29), {'id': 29}), (25, np.int64(30), {'id': 30}), (25, np.int64(31), {'id': 31}), (25, np.int64(32), {'id': 32}), (25, np.int64(33), {'id': 33}), (25, np.int64(34), {'id': 34}), (27, 63, {'id': 116}), (27, 89, {'id': 155}), (27, 91, {'id': 159}), (27, 92, {'id': 160}), (28, 36, {'id': 42}), (30, 43, {'id': 67}), (35, np.int64(36), {'id': 35}), (36, np.int64(46), {'id': 43}), (36, np.int64(47), {'id': 44}), (36, np.int64(50), {'id': 45}), (36, np.int64(58), {'id': 46}), (36, np.int64(59), {'id': 47}), (36, np.int64(60), {'id': 48}), (36, np.int64(61), {'id': 49}), (36, np.int64(63), {'id': 50}), (36, np.int64(66), {'id': 51}), (36, np.int64(67), {'id': 52}), (36, np.int64(68), {'id': 53}), (36, np.int64(69), {'id': 54}), (36, np.int64(70), {'id': 55}), (36, np.int64(71), {'id': 56}), (36, np.int64(72), {'id': 57}), (36, np.int64(73), {'id': 58}), (36, np.int64(74), {'id': 59}), (36, 45, {'id': 81}), (37, np.int64(38), {'id': 61}), (37, 84, {'id': 147}), (38, 84, {'id': 148}), (39, np.int64(40), {'id': 62}), (40, 62, {'id': 107}), (42, np.int64(43), {'id': 64}), (42, np.int64(44), {'id': 65}), (43, np.int64(49), {'id': 68}), (43, np.int64(61), {'id': 103}), (43, np.int64(62), {'id': 70}), (43, np.int64(63), {'id': 71}), (43, 44, {'id': 72}), (45, np.int64(46), {'id': 82}), (45, np.int64(47), {'id': 83}), (45, np.int64(48), {'id': 84}), (45, np.int64(49), {'id': 85}), (45, np.int64(50), {'id': 86}), (45, np.int64(51), {'id': 87}), (45, np.int64(52), {'id': 88}), (45, np.int64(53), {'id': 89}), (45, np.int64(54), {'id': 90}), (45, np.int64(55), {'id': 91}), (45, np.int64(56), {'id': 92}), (45, np.int64(57), {'id': 93}), (45, np.int64(58), {'id': 94}), (45, np.int64(59), {'id': 95}), (45, np.int64(60), {'id': 96}), (48, 82, {'id': 135}), (49, 61, {'id': 104}), (50, 62, {'id': 108}), (53, np.int64(54), {'id': 100}), (53, np.int64(80), {'id': 98}), (53, np.int64(81), {'id': 131}), (53, 98, {'id': 169}), (54, 81, {'id': 132}), (54, 98, {'id': 170}), (55, 56, {'id': 101}), (57, 84, {'id': 149}), (58, 62, {'id': 109}), (59, 62, {'id': 110}), (60, 62, {'id': 111}), (61, 95, {'id': 166}), (62, np.int64(74), {'id': 112}), (62, np.int64(77), {'id': 113}), (62, np.int64(78), {'id': 114}), (62, np.int64(79), {'id': 115}), (63, np.int64(93), {'id': 117}), (63, np.int64(94), {'id': 118}), (63, 92, {'id': 161}), (64, np.int64(65), {'id': 120}), (66, np.int64(67), {'id': 121}), (66, np.int64(68), {'id': 123}), (67, 68, {'id': 124}), (69, 89, {'id': 156}), (71, np.int64(75), {'id': 127}), (71, np.int64(76), {'id': 128}), (72, np.int64(88), {'id': 129}), (82, np.int64(83), {'id': 136}), (82, np.int64(84), {'id': 137}), (83, 84, {'id': 150}), (84, np.int64(85), {'id': 151}), (84, np.int64(86), {'id': 152}), (84, np.int64(87), {'id': 153}), (85, 86, {'id': 154}), (87, 99, {'id': 172}), (90, np.int64(91), {'id': 158}), (92, np.int64(93), {'id': 162}), (92, np.int64(94), {'id': 163}), (95, np.int64(96), {'id': 167}), (97, np.int64(98), {'id': 168})]\n"
     ]
    },
    {
     "ename": "NetworkXNotImplemented",
     "evalue": "not implemented for multigraph type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNetworkXNotImplemented\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/DREAM4/DREAM4_InSilico_Size100/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m org, files \u001b[38;5;129;01min\u001b[39;00m InsilicoSize100_org\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 3\u001b[0m     basic_data,basic_TS_data,basic_aug_data,basic_TS_aug_data \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_grn_to_dgl_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 117\u001b[0m, in \u001b[0;36mconvert_grn_to_dgl_graph\u001b[0;34m(file_hetero, file_null, file_traject, file_gold)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m############    \u001b[39;00m\n\u001b[1;32m    116\u001b[0m pagerank \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mpagerank(G)\n\u001b[0;32m--> 117\u001b[0m clustering_coef \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclustering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m betweenness_centrality \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mbetweenness_centrality(G, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m    119\u001b[0m degree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(G\u001b[38;5;241m.\u001b[39mdegree())\n",
      "File \u001b[0;32m~/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/networkx/utils/backends.py:412\u001b[0m, in \u001b[0;36m_dispatch.__call__\u001b[0;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backends:\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;66;03m# Fast path if no backends are installed\u001b[39;00m\n\u001b[0;32m--> 412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morig_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# Use `backend_name` in this function instead of `backend`\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m backend\n",
      "File \u001b[0;32m~/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/networkx/algorithms/cluster.py:419\u001b[0m, in \u001b[0;36mclustering\u001b[0;34m(G, nodes, weight)\u001b[0m\n\u001b[1;32m    417\u001b[0m         clusterc \u001b[38;5;241m=\u001b[39m {v: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t \u001b[38;5;241m/\u001b[39m (d \u001b[38;5;241m*\u001b[39m (d \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m v, d, t \u001b[38;5;129;01min\u001b[39;00m td_iter}\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m         td_iter \u001b[38;5;241m=\u001b[39m \u001b[43m_triangles_and_degree_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m         clusterc \u001b[38;5;241m=\u001b[39m {v: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t \u001b[38;5;241m/\u001b[39m (d \u001b[38;5;241m*\u001b[39m (d \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m v, d, t, _ \u001b[38;5;129;01min\u001b[39;00m td_iter}\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nodes \u001b[38;5;129;01min\u001b[39;00m G:\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# Return the value of the sole entry in the dictionary.\u001b[39;00m\n",
      "File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 4:3\u001b[0m, in \u001b[0;36margmap__triangles_and_degree_iter_1\u001b[0;34m(G, nodes)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbz2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/networkx/utils/decorators.py:90\u001b[0m, in \u001b[0;36mnot_implemented_for.<locals>._not_implemented_for\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_not_implemented_for\u001b[39m(g):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (mval \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m mval \u001b[38;5;241m==\u001b[39m g\u001b[38;5;241m.\u001b[39mis_multigraph()) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m     88\u001b[0m         dval \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m dval \u001b[38;5;241m==\u001b[39m g\u001b[38;5;241m.\u001b[39mis_directed()\n\u001b[1;32m     89\u001b[0m     ):\n\u001b[0;32m---> 90\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m nx\u001b[38;5;241m.\u001b[39mNetworkXNotImplemented(errmsg)\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m g\n",
      "\u001b[0;31mNetworkXNotImplemented\u001b[0m: not implemented for multigraph type"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"./data/DREAM4/DREAM4_InSilico_Size100/\"\n",
    "for org, files in InsilicoSize100_org.items():\n",
    "    basic_data,basic_TS_data,basic_aug_data,basic_TS_aug_data = convert_grn_to_dgl_graph(files[1],files[2],files[3],files[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GRNXAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
