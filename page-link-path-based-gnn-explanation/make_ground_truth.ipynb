{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/younggun0816/anaconda3/envs/GRNXAI/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from data_grn_processing import load_grn_dataset_dgl\n",
    "from model_grn import GRNGNN, prediction_dgl\n",
    "from utils import set_config_args, get_comp_g_edge_labels, get_comp_g_path_labels\n",
    "from utils import src_tgt_khop_in_subgraph, eval_edge_mask_auc, eval_edge_mask_topk_path_hit\n",
    "from explainer_grn import PaGELink\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DGL 그래프에서 feature dimension 가져오기 (feat이 아닌 모든 ndata 속성 사용)\n",
    "def get_in_dim(mp_g):\n",
    "    \"\"\"\n",
    "    DGL 그래프에서 모든 노드 feature의 총 차원을 계산하는 함수\n",
    "    \"\"\"\n",
    "    node_feats = []\n",
    "    for key in mp_g.ndata.keys():  # 모든 노드 feature 속성 확인\n",
    "        feat = mp_g.ndata[key]  # 해당 feature 텐서 가져오기\n",
    "        if len(feat.shape) == 2:  # (num_nodes, feature_dim) 형태일 경우만 추가\n",
    "            node_feats.append(feat.shape[1])\n",
    "    \n",
    "    if not node_feats:\n",
    "        raise ValueError(\"No valid node features found in graph! Check ndata.\")\n",
    "\n",
    "    return sum(node_feats)  # 모든 feature 차원을 더해서 총 in_dim 반환\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() and device_id >= 0:\n",
    "    device = torch.device('cuda', index=device_id)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"datasets\"\n",
    "dataset_name = \"Ecoli1_basic_graph\"\n",
    "valid_ratio = 0.1\n",
    "test_ratio = 0.2\n",
    "g, processed_g = load_grn_dataset_dgl(dataset_dir,dataset_name, valid_ratio, test_ratio)\n",
    "mp_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g = [g.to(device) for g in processed_g]\n",
    "\n",
    "try:\n",
    "    in_dim = get_in_dim(mp_g)\n",
    "except KeyError:\n",
    "    raise ValueError(\"Graph does not contain 'feat' in node features. Ensure features are properly assigned.\")\n",
    "\n",
    "hidden_dim_1 = 128\n",
    "hidden_dim_2 = 64\n",
    "out_dim = 32\n",
    "af_val = \"F.silu\"\n",
    "dec = \"dot_sum\"\n",
    "num_layers = 4\n",
    "num_epochs = 20\n",
    "aggr = \"sum\"\n",
    "var = \"ChebConv\"\n",
    "saved_model_dir = \"saved_models\"\n",
    "saved_modal_name = \"basic_data_Ecoli1_InSilicoSize100_model\"\n",
    "\n",
    "\n",
    "model = GRNGNN(in_dim, hidden1_channels=128, hidden2_channels=64, out_channels=32, dec='dot_sum', af_val='F.silu', num_layers=4, epoch=20, aggr='sum', var='ChebConv').to(device)\n",
    "state = torch.load(f'saved_models/basic_data_Ecoli1_InSilicoSize100_model.pth', map_location='cuda')\n",
    "model.load_state_dict(state) \n",
    "\n",
    "pagelink = PaGELink(model, \n",
    "                    lr=0.01,\n",
    "                    alpha=1.0, \n",
    "                    beta=1.0, \n",
    "                    num_epochs=20,\n",
    "                    log=True,\n",
    "                    af_val='F.silu').to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of pred_pair_to_edge_labels: <class 'dict'>\n",
      "Type of pred_pair_to_path_labels: <class 'collections.defaultdict'>\n",
      "Length of pred_pair_to_edge_labels: 4501\n",
      "Length of pred_pair_to_path_labels: 4501\n",
      "Sample keys in pred_pair_to_edge_labels: [(('author', 1), ('paper', np.int64(2217)))]\n",
      "Sample keys in pred_pair_to_path_labels: [(('author', 1), ('paper', np.int64(2217)))]\n"
     ]
    }
   ],
   "source": [
    "from data_processing import load_dataset\n",
    "valid_ratio = 0.1\n",
    "test_ratio = 0.2\n",
    "dataset_name = \"aug_citation\"\n",
    "dataset_dir = 'datasets'\n",
    "\n",
    "g, processed_g, pred_pair_to_edge_labels, pred_pair_to_path_labels = load_dataset(dataset_dir,\n",
    "                                                                                  dataset_name,\n",
    "                                                                                  valid_ratio,\n",
    "                                                                                  test_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Type of pred_pair_to_edge_labels:\", type(pred_pair_to_edge_labels))\n",
    "print(\"Type of pred_pair_to_path_labels:\", type(pred_pair_to_path_labels))\n",
    "print(\"Length of pred_pair_to_edge_labels:\", len(pred_pair_to_edge_labels))\n",
    "print(\"Length of pred_pair_to_path_labels:\", len(pred_pair_to_path_labels))\n",
    "\n",
    "\n",
    "print(\"Sample keys in pred_pair_to_edge_labels:\", list(pred_pair_to_edge_labels.keys())[:1])\n",
    "print(\"Sample keys in pred_pair_to_path_labels:\", list(pred_pair_to_path_labels.keys())[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample keys in pred_pair_to_edge_labels: [(('author', 1), ('paper', np.int64(2217)))]\n",
      "Sample keys in pred_pair_to_path_labels: [(('author', 1), ('paper', np.int64(2217)))]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample keys in pred_pair_to_edge_labels:\", list(pred_pair_to_edge_labels.keys())[:1])\n",
    "print(\"Sample keys in pred_pair_to_path_labels:\", list(pred_pair_to_path_labels.keys())[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'set'>, {('author', 'writes', 'paper'): (tensor([1, 1]), tensor([529, 212])), ('paper', 'in', 'fos'): (tensor([529, 212]), tensor([812, 812])), ('fos', 'of', 'paper'): (tensor([812]), tensor([2217]))})\n"
     ]
    }
   ],
   "source": [
    "key = (('author', 1), ('paper', np.int64(2217)))  # 해당 키를 변수에 저장\n",
    "value = pred_pair_to_edge_labels[key]  # 딕셔너리에서 키로 값 조회\n",
    "print(value)  # 값 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(tensor(212), tensor(812)), (tensor(529), tensor(812))}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(set(zip(torch.tensor([529, 212]), torch.tensor([812, 812]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(('author', 'writes', 'paper'), 1, 529), (('paper', 'in', 'fos'), 529, 812), (('fos', 'of', 'paper'), 812, 2217)], [(('author', 'writes', 'paper'), 1, 212), (('paper', 'in', 'fos'), 212, 812), (('fos', 'of', 'paper'), 812, 2217)]]\n"
     ]
    }
   ],
   "source": [
    "key = (('author', 1), ('paper', np.int64(2217)))  # 해당 키를 변수에 저장\n",
    "value = pred_pair_to_path_labels[key]  # 딕셔너리에서 키로 값 조회\n",
    "print(value)  # 값 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=100, num_edges=173,\n",
      "      ndata_schemes={'wildtype': Scheme(shape=(1,), dtype=torch.float32), 'id': Scheme(shape=(1,), dtype=torch.float32)}\n",
      "      edata_schemes={'KD': Scheme(shape=(1,), dtype=torch.float32), 'KO': Scheme(shape=(1,), dtype=torch.float32)})\n",
      "173\n",
      "<class 'numpy.ndarray'>\n",
      "[ 1.40120630e+03  3.55243848e+03  5.89308301e+03  1.02057373e+04\n",
      "  1.19388418e+04  1.40031113e+04  1.61383174e+04 -2.08246914e+04\n",
      "  2.00330586e+04  2.18680156e+04  2.39251426e+04  2.58888828e+04\n",
      "  2.76326660e+04  2.97433340e+04  3.16176836e+04  3.35535117e+04\n",
      "  3.57002969e+04  3.76867383e+04  3.96445039e+04  4.15748906e+04\n",
      "  4.62188312e+05  2.22560450e+06 -2.00040922e+05  9.22621094e+04\n",
      "  1.35639781e+05  1.71262285e+04  3.25263031e+05  3.38506938e+05\n",
      "  3.51278406e+05  3.63046062e+05  3.76481812e+05  3.89492875e+05\n",
      "  4.01435000e+05  4.14375844e+05  4.25605312e+05 -1.16599078e+05\n",
      "  3.41255188e+01 -2.35964102e+04  4.62188312e+05  7.46156172e+04\n",
      " -7.68391250e+04  6.37151211e+04 -9.34809766e+04 -1.53277906e+05\n",
      " -1.56611750e+05 -1.66699281e+05 -1.93657531e+05 -1.96911594e+05\n",
      " -2.00395562e+05  1.64911531e+05  1.57287406e+05  3.00552090e+04\n",
      " -2.23580516e+05  2.77728340e+04 -2.30434906e+05 -2.33615688e+05\n",
      " -2.13469453e+05 -1.93167188e+05 -2.43744312e+05 -1.46835250e+05\n",
      "  1.09643562e+05  5.13683438e+05  7.85085812e+05 -2.73318481e+02\n",
      " -4.87508375e+05  8.15802500e+05  2.22560450e+06 -3.49169250e+05\n",
      " -5.69048250e+05  5.20345250e+05 -3.05541125e+05  4.91628969e+05\n",
      " -2.72144062e+04  6.67845938e+04  1.84290578e+05 -1.84346656e+05\n",
      "  3.40092781e+05  3.61513438e+05  3.83663312e+05  4.75556094e+05\n",
      "  5.20990438e+05 -1.49957656e+05  1.03973556e+06  1.06239000e+06\n",
      "  1.08646975e+06  1.10998788e+06  1.13107075e+06  1.15329425e+06\n",
      "  1.17680975e+06 -1.99150812e+06 -2.14231700e+06  1.24463050e+06\n",
      "  1.21953850e+06  1.29133938e+06  1.31467500e+06  1.33665825e+06\n",
      "  1.36055725e+06  1.47563380e+07 -3.54893100e+06  4.76171500e+06\n",
      "  1.47563380e+07  1.49267688e+06  6.78959375e+05  5.20345250e+05\n",
      "  9.72338125e+04  3.33720625e+05  3.52291875e+05  7.40833312e+05\n",
      "  9.24034562e+05  1.07387038e+06  1.09184750e+06  1.11131438e+06\n",
      "  1.11453500e+06  1.42605275e+06  1.44420650e+06  1.46323875e+06\n",
      "  7.53974062e+04  2.60778844e+05  2.63472812e+05  1.19381562e+04\n",
      "  1.19381562e+04  3.89969625e+05  1.41608141e+05  1.41608141e+05\n",
      "  4.09221562e+05  4.09847250e+05  7.74740562e+05  2.52527125e+06\n",
      "  2.56328000e+06  2.82182700e+06  6.86338812e+05  4.76171500e+06\n",
      "  5.53789550e+06  7.45150188e+05  7.86666500e+05  1.98275800e+06\n",
      "  3.43418250e+06  3.39562450e+06  1.21079062e+05  3.36492500e+05\n",
      "  4.18107781e+05  4.56278875e+05  4.99604719e+05  6.21279188e+05\n",
      "  6.60306125e+05  7.00758500e+05  3.13352594e+05  1.20162012e+06\n",
      "  1.57504675e+06  2.36189200e+06  3.44250350e+06  3.52457475e+06\n",
      "  3.13118450e+06  3.60948850e+06  3.06749900e+06  1.21014575e+06\n",
      "  3.10017150e+06  9.08576688e+05  3.62479400e+06  1.08351575e+06\n",
      "  1.25085775e+06  2.57753531e+05  4.31600350e+06  4.36083100e+06\n",
      " -3.85072875e+05  9.59189312e+05  1.88572969e+05  4.60350550e+06\n",
      "  4.20764700e+06 -3.24526725e+06 -3.19087175e+06 -4.01123469e+05\n",
      "  4.34993700e+06]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred, pos = prediction_dgl(model, mp_g, af_val, dec)\n",
    "\n",
    "print(mp_g)\n",
    "\n",
    "print(len(pred))\n",
    "print(type(pred))\n",
    "print(pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_src_nids, test_tgt_nids = test_pos_g.edges()\n",
    "comp_graphs = defaultdict(list)\n",
    "comp_g_labels = defaultdict(list)\n",
    "num_hops = 2\n",
    "i = 4\n",
    "# Get the k-hop subgraph\n",
    "src_nid, tgt_nid = test_src_nids[i], test_tgt_nids[i]\n",
    "comp_g_src_nid, comp_g_tgt_nid, comp_g, comp_g_feat_nids, comp_g_eids = src_tgt_khop_in_subgraph( src_nid,\n",
    "                                                                                     tgt_nid,\n",
    "                                                                                            mp_g,\n",
    "                                                                                            num_hops)\n",
    "with torch.no_grad():\n",
    "    pred, pos = prediction_dgl(model, mp_g, af_val, dec)\n",
    "\n",
    "\n",
    "# Extract edges from the graph\n",
    "edge_index = torch.stack(comp_g.edges(), dim=0).cpu().numpy()\n",
    "src_tgt_pair = np.array([comp_g_src_nid.cpu().numpy(), comp_g_tgt_nid.cpu().numpy()]).reshape(2, 1)\n",
    "\n",
    "# Check if the prediction contains this specific edge\n",
    "mask = np.all(edge_index == src_tgt_pair, axis=0)\n",
    "\n",
    "if mask.sum() > 0 and pred[mask][0]:  # src_nid -> tgt_nid에 대한 예측 값이 1인지 확인\n",
    "    src_tgt = (int(src_nid), int(tgt_nid))\n",
    "    comp_graphs[src_tgt] = [comp_g_src_nid, comp_g_tgt_nid, comp_g, comp_g_feat_nids]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GRNXAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
