{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from data_grn_processing import load_grn_dataset_dgl\n",
    "from model_grn import GRNGNN, prediction_dgl\n",
    "from utils import set_config_args, get_comp_g_edge_labels, get_comp_g_path_labels\n",
    "from utils import src_tgt_khop_in_subgraph, eval_edge_mask_auc, eval_edge_mask_topk_path_hit\n",
    "\n",
    "\n",
    "# DGL 그래프에서 feature dimension 가져오기 (feat이 아닌 모든 ndata 속성 사용)\n",
    "def get_in_dim(mp_g):\n",
    "    \"\"\"\n",
    "    DGL 그래프에서 모든 노드 feature의 총 차원을 계산하는 함수\n",
    "    \"\"\"\n",
    "    node_feats = []\n",
    "    for key in mp_g.ndata.keys():  # 모든 노드 feature 속성 확인\n",
    "        feat = mp_g.ndata[key]  # 해당 feature 텐서 가져오기\n",
    "        if len(feat.shape) == 2:  # (num_nodes, feature_dim) 형태일 경우만 추가\n",
    "            node_feats.append(feat.shape[1])\n",
    "    \n",
    "    if not node_feats:\n",
    "        raise ValueError(\"No valid node features found in graph! Check ndata.\")\n",
    "\n",
    "    return sum(node_feats)  # 모든 feature 차원을 더해서 총 in_dim 반환\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Explain link predictor')\n",
    "'''\n",
    "Dataset args\n",
    "'''\n",
    "parser.add_argument('--dataset_dir', type=str, default='datasets')\n",
    "parser.add_argument('--dataset_name', type=str, default='aug_citation')\n",
    "parser.add_argument('--valid_ratio', type=float, default=0.1) \n",
    "parser.add_argument('--test_ratio', type=float, default=0.2)\n",
    "parser.add_argument('--max_num_samples', type=int, default=-1, \n",
    "                    help='maximum number of samples to explain, for fast testing. Use all if -1')\n",
    "\n",
    "'''\n",
    "GNN args\n",
    "'''\n",
    "parser.add_argument('--hidden_dim_1', type=int, default=128)\n",
    "parser.add_argument('--hidden_dim_2', type=int, default=64)\n",
    "parser.add_argument('--out_dim', type=int, default=32)\n",
    "parser.add_argument('--saved_model_dir', type=str, default='saved_models')\n",
    "parser.add_argument('--saved_model_name', type=str, default='')\n",
    "\n",
    "'''\n",
    "Explanation args\n",
    "'''\n",
    "parser.add_argument('--num_hops', type=int, default=2, help='computation graph number of hops') \n",
    "parser.add_argument('--saved_explanation_dir', type=str, default='saved_explanations',\n",
    "                    help='directory of saved explanations')\n",
    "parser.add_argument('--eval_explainer_names', nargs='+', default=['pagelink'],\n",
    "                    help='name of explainers to evaluate') \n",
    "parser.add_argument('--eval_path_hit', default=False, action='store_true', \n",
    "                    help='Whether to save the explanation') \n",
    "parser.add_argument('--config_path', type=str, default='', help='path of saved configuration args')\n",
    "\n",
    "'''\n",
    "'''\n",
    "\n",
    "parser.add_argument('--dec', type=str, default='dot_sum', choices=['dot', 'cos', 'ele', 'cat', 'dot_sum'],\n",
    "                   help='Edge predictor에서 사용할 디코딩 연산 방식')\n",
    "parser.add_argument('--af_val', type=str, default='F.silu', choices=['F.silu', 'F.sigmoid', 'F.tanh'],\n",
    "                   help='Edge predictor에서 사용할 활성화 함수')\n",
    "parser.add_argument('--var', type=str, default='ChebConv', choices=['ChebConv', 'SSGConv', 'ClusterGCNConv', 'HypergraphConv'],\n",
    "                   help='GNN 변형 방식 선택')\n",
    "parser.add_argument('--num_layers', type=int, default=3,\n",
    "                   help='GNN의 레이어 개수')\n",
    "parser.add_argument('--aggr', type=str, default='sum', choices=['sum', 'add'],\n",
    "                   help='operation passed to dgl.EdgePredictor')\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args('')\n",
    "\n",
    "if args.config_path:\n",
    "    args = set_config_args(args, args.config_path, args.dataset_name, 'train_eval')  \n",
    "\n",
    "\n",
    "if torch.cuda.is_available() and args.device_id >= 0:\n",
    "    device = torch.device('cuda', index=args.device_id)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "\n",
    "g, processed_g = load_grn_dataset_dgl(args.dataset_dir,\n",
    "                                                                                  args.dataset_name,\n",
    "                                                                                  args.valid_ratio,\n",
    "                                                                                  args.test_ratio)\n",
    "mp_g, train_pos_g, train_neg_g, val_pos_g, val_neg_g, test_pos_g, test_neg_g = [g for g in processed_g]\n",
    "\n",
    "\n",
    "try:\n",
    "    in_dim = get_in_dim(mp_g)\n",
    "except KeyError:\n",
    "    raise ValueError(\"Graph does not contain 'feat' in node features. Ensure features are properly assigned.\")\n",
    "\n",
    "\n",
    "model = GRNGNN(in_dim, args.hidden_dim_1, args.hidden_dim_2, args.out_dim,args.dec,args.af_val,args.num_layers,args.num_epochs,args.aggr,args.var).to(device)#Net(data.num_features, data.num_features, 128, 64).to(device) #self, in_channels, hidden1_channels, hidden2_channels,out_channels\n",
    "\n",
    "\n",
    "if not args.saved_model_name:\n",
    "    args.saved_model_name = f'{args.dataset_name}_model'\n",
    "\n",
    "state = torch.load(f'{args.saved_model_dir}/{args.saved_model_name}.pth', map_location='cuda')\n",
    "model.load_state_dict(state)    \n",
    "\n",
    "test_src_nids, test_tgt_nids = test_pos_g.edges()\n",
    "comp_graphs = defaultdict(list)\n",
    "comp_g_labels = defaultdict(list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick one example graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "# Get the k-hop subgraph\n",
    "src_nid, tgt_nid = test_src_nids[i], test_tgt_nids[i]\n",
    "comp_g_src_nid, comp_g_tgt_nid, comp_g, comp_g_feat_nids = src_tgt_khop_in_subgraph( src_nid,\n",
    "                                                                                     tgt_nid,\n",
    "                                                                                            mp_g,\n",
    "                                                                                            args.num_hops)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = prediction_dgl(model, mp_g, args.af_val, args.dec)\n",
    "\n",
    "if pred:\n",
    "    src_tgt = (int(src_nid), int(tgt_nid))\n",
    "    comp_graphs[src_tgt] = [comp_g_src_nid, comp_g_tgt_nid, comp_g, comp_g_feat_nids]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = args.eval_explainer_names[0]\n",
    "saved_explanation_mask = f'{explainer}_{args.saved_model_name}_pred_edge_to_comp_g_edge_mask'\n",
    "saved_file = Path.cwd().joinpath(args.saved_explanation_dir, saved_explanation_mask)\n",
    "with open(saved_file, \"rb\") as f:\n",
    "    explanation_mask = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract paths and construct the explanation graph to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "def get_exp_g(g, paths, src_nid, tgt_nid):\n",
    "    path_eids = {}\n",
    "    for path in paths:\n",
    "        for edge in path:\n",
    "            u, v = edge\n",
    "            eids = comp_g.edge_ids(u, v)\n",
    "            path_eids[(u, v)] = eids\n",
    "\n",
    "    exp_g = g\n",
    "\n",
    "    remove_eids = g.edges(form='eid')\n",
    "    if path_eids:\n",
    "        mask = torch.ones(remove_eids.shape, dtype=torch.bool)\n",
    "        mask[path_eids] = False  # path_eids에 있는 엣지는 유지\n",
    "        remove_eids = remove_eids[mask]  # 제거할 엣지만 남기기\n",
    "\n",
    "    exp_g = dgl.remove_edges(exp_g, remove_eids) # creates a new graph\n",
    "\n",
    "    exp_g = dgl.compact_graphs(exp_g)\n",
    "\n",
    "    # Get src and tgt nid in the explanation graph\n",
    "    # Note: the input graph should have node data dgl.NID\n",
    "    exp_g_src_nid_in_g = exp_g.ndata[dgl.NID]\n",
    "    exp_g_src_nid = (exp_g_src_nid_in_g == src_nid).nonzero().view(-1)\n",
    "    exp_g_tgt_nid = (exp_g_src_nid_in_g == tgt_nid).nonzero().view(-1)\n",
    "\n",
    "    return exp_g, exp_g_src_nid, exp_g_tgt_nid   \n",
    "\n",
    "comp_g_edge_mask_dict = explanation_mask[src_tgt]\n",
    "from explainer_grn import PaGELink\n",
    "pagelink = PaGELink(model)\n",
    "paths = pagelink.get_paths(comp_g_src_nid, comp_g_tgt_nid, comp_g, comp_g_edge_mask_dict)\n",
    "\n",
    "exp_g, exp_g_src_nid, exp_g_tgt_nid = get_exp_g(comp_g, \n",
    "                                                paths,\n",
    "                                                comp_g_src_nid,\n",
    "                                                comp_g_tgt_nid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set plot arguments and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_homo_graph\n",
    "\n",
    "edge_kwargs = {\"edge_color\" : '#00B050',\n",
    "               \"style\" : '-',\n",
    "               \"width\" : 4,\n",
    "               \"arrows\" : True,\n",
    "               \"arrowstyle\" : '-|>',\n",
    "               \"arrowsize\" : 30}\n",
    "\n",
    "selected_edge_kwargs = {\"edge_color\" : 'red',\n",
    "                        \"style\" : '--',\n",
    "                        \"width\" : 3,\n",
    "                        \"arrows\" : False}\n",
    "selected_edges = list(zip(exp_g_src_nid.tolist(), exp_g_tgt_nid.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = plot_homo_graph(exp_g,\n",
    "                             label='nx_id',\n",
    "                             edge_kwargs=edge_kwargs,\n",
    "                             selected_edge_kwargs=selected_edge_kwargs,\n",
    "                             selected_edge=selected_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GRNXAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
